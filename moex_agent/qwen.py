from __future__ import annotations

import json
import logging
from dataclasses import dataclass
from datetime import datetime, timezone
from typing import Any, Dict, Optional

import requests

logger = logging.getLogger("moex_agent.qwen")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ñ‚Ğ¸ĞºĞµÑ€Ğ¾Ğ² Ğ¿Ğ¾ Ğ»Ğ¸ĞºĞ²Ğ¸Ğ´Ğ½Ğ¾ÑÑ‚Ğ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Tier 1 â€” Blue chips (Ğ²Ñ‹ÑÑˆĞ°Ñ Ğ»Ğ¸ĞºĞ²Ğ¸Ğ´Ğ½Ğ¾ÑÑ‚ÑŒ, Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ°Ğ³Ñ€ĞµÑÑĞ¸Ğ²Ğ½ĞµĞµ)
LIQUID_TICKERS = {
    "SBER", "SBERP", "GAZP", "LKOH", "ROSN", "NVTK", "GMKN", "SIBN",
    "T", "YDEX", "VTBR", "PLZL"
}

# Tier 2 â€” Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ Ğ»Ğ¸ĞºĞ²Ğ¸Ğ´Ğ½Ğ¾ÑÑ‚ÑŒ (ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´)
MEDIUM_TICKERS = {
    "TATN", "TATNP", "SNGS", "SNGSP", "OZON", "X5", "MTSS", "CHMF",
    "NLMK", "MAGN", "ALRS", "MOEX", "AFLT", "POSI", "IRAO", "HYDR",
    "FEES", "RUAL", "MGNT", "SMLT", "SFIN", "SOFL", "SPBE", "VKCO",
    "PHOR", "TRNFP", "FLOT"
}

# Tier 3 â€” ĞĞ¸Ğ·ĞºĞ°Ñ Ğ»Ğ¸ĞºĞ²Ğ¸Ğ´Ğ½Ğ¾ÑÑ‚ÑŒ (ĞºĞ¾Ğ½ÑĞµÑ€Ğ²Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾, Ğ±ĞµĞ· ÑˆĞ¾Ñ€Ñ‚Ğ¾Ğ²)
# Ğ’ÑĞµ Ğ¾ÑÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ: PIKK, CBOM, HEAD, LENT, OKEY, ENPG, RSTI, ...

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# System prompt Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²Ñ‹Ñ… ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ²
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SYSTEM_PROMPT = """Ğ¢Ñ‹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸Ğº Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²Ñ‹Ñ… ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ² Ğ´Ğ»Ñ Ñ€Ğ¾ÑÑĞ¸Ğ¹ÑĞºĞ¾Ğ³Ğ¾ Ñ€Ñ‹Ğ½ĞºĞ° Ğ°ĞºÑ†Ğ¸Ğ¹ (MOEX).

## Ğ¢Ğ²Ğ¾Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°
ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğ¹ ÑĞ¸Ğ³Ğ½Ğ°Ğ» Ğ¸ Ğ²ĞµÑ€Ğ½ÑƒÑ‚ÑŒ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ JSON Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¾Ğ¹.

## Ğ’Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
- ticker: Ñ‚Ğ¸ĞºĞµÑ€ Ğ°ĞºÑ†Ğ¸Ğ¸
- direction: LONG (Ğ¿Ğ¾ĞºÑƒĞ¿ĞºĞ°) Ğ¸Ğ»Ğ¸ SHORT (Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğ°)
- horizon: Ğ³Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚ ÑĞ´ĞµĞ»ĞºĞ¸ (5m, 10m, 30m, 1h, 1d, 1w)
- p: Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ ÑƒÑĞ¿ĞµÑ…Ğ° Ğ¾Ñ‚ ML-Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (0.0 - 1.0)
- signal_type: "price-exit" Ğ¸Ğ»Ğ¸ "time-exit"
- entry/take/stop: ÑƒÑ€Ğ¾Ğ²Ğ½Ğ¸ Ñ†ĞµĞ½
- anomaly: Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ğ¸
  - score: ÑĞ¸Ğ»Ğ° Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ğ¸
  - z_ret_5m: z-score Ğ´Ğ¾Ñ…Ğ¾Ğ´Ğ½Ğ¾ÑÑ‚Ğ¸
  - z_vol_5m: z-score Ğ¾Ğ±ÑŠÑ‘Ğ¼Ğ°
  - volume_spike: Ğ²ÑĞ¿Ğ»ĞµÑĞº Ğ¾Ğ±ÑŠÑ‘Ğ¼Ğ° (1.0 = Ğ½Ğ¾Ñ€Ğ¼Ğ°, 2.0 = Ğ² 2 Ñ€Ğ°Ğ·Ğ° Ğ²Ñ‹ÑˆĞµ)
  - spread_bps: ÑĞ¿Ñ€ĞµĞ´ Ğ² Ğ±.Ğ¿.
- market_context: Ğ²Ñ€ĞµĞ¼Ñ Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ², Ğ»Ğ¸ĞºĞ²Ğ¸Ğ´Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‚Ğ¸ĞºĞµÑ€Ğ°

## ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»Ğ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°

### ĞšĞ¾Ğ³Ğ´Ğ° ĞĞ¢ĞšĞ›ĞĞĞ˜Ğ¢Ğ¬ (skip: true):
1. p < 0.30 â€” Ğ½Ğ¸Ğ·ĞºĞ°Ñ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ (Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ĞºĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ°, max â‰ˆ 0.60)
2. |z_ret| < 0.5 Ğ¸ |z_vol| < 0.5 â€” Ğ½ĞµÑ‚ Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ğ¸
3. ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ Ğ³Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚ + ÑˆĞ¸Ñ€Ğ¾ĞºĞ¸Ğ¹ ÑĞ¿Ñ€ĞµĞ´ â€” Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğµ Ğ¸Ğ·Ğ´ĞµÑ€Ğ¶ĞºĞ¸
4. ĞŸĞµÑ€Ğ²Ñ‹Ğµ 15 Ğ¼Ğ¸Ğ½ Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ² + Ğ½Ğ¸Ğ·ĞºĞ¸Ğ¹ score â€” ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğ¹ ÑˆÑƒĞ¼
5. SHORT + Ğ½Ğ¸Ğ·ĞºĞ¾Ğ»Ğ¸ĞºĞ²Ğ¸Ğ´Ğ½Ñ‹Ğ¹ Ñ‚Ğ¸ĞºĞµÑ€ â€” ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ ÑˆĞ¾Ñ€Ñ‚Ğ¸Ñ‚ÑŒ

### Ğ£Ñ€Ğ¾Ğ²Ğ½Ğ¸ Ñ€Ğ¸ÑĞºĞ° (calibrated model):
- LOW: p > 0.45, |z_ret| > 1.5, spread < 20, volume_spike > 1.5
- MEDIUM: p > 0.38, |z_ret| > 1.0, spread < 35
- HIGH: Ğ¾ÑÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ

## Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° (Ğ¢ĞĞ›Ğ¬ĞšĞ JSON)
{
  "skip": false,
  "risk_level": "LOW|MEDIUM|HIGH",
  "confidence": 0.85,
  "reasoning": "ĞĞ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ (1-2 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ)",
  "risk_note": "ĞŸÑ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Telegram",
  "recommendation": "STRONG_BUY|BUY|WEAK_BUY|STRONG_SELL|SELL|WEAK_SELL|SKIP"
}
"""


@dataclass
class QwenAnalysis:
    """Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ°."""
    skip: bool
    risk_level: str
    confidence: float
    reasoning: str
    risk_note: str
    recommendation: str
    skip_reason: Optional[str] = None
    raw_response: Optional[Dict] = None


def _get_market_context() -> Dict[str, Any]:
    """ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ñ€Ñ‹Ğ½ĞºĞ° (Ğ²Ñ€ĞµĞ¼Ñ Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²)."""
    now = datetime.now(timezone.utc)
    moscow_hour = (now.hour + 3) % 24  # UTC+3

    # MOEX Ñ‚Ğ¾Ñ€Ğ³Ğ¸: 10:00-18:50 MSK
    is_trading = 10 <= moscow_hour < 19

    # ĞŸĞµÑ€Ğ²Ñ‹Ğµ 15 Ğ¼Ğ¸Ğ½ÑƒÑ‚
    is_opening = moscow_hour == 10 and now.minute < 15

    # ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 30 Ğ¼Ğ¸Ğ½ÑƒÑ‚
    is_closing = moscow_hour == 18 and now.minute >= 20

    return {
        "moscow_hour": moscow_hour,
        "is_trading": is_trading,
        "is_opening": is_opening,
        "is_closing": is_closing,
        "day_of_week": now.weekday(),  # 0=Mon, 4=Fri
    }


def _get_ticker_liquidity(ticker: str) -> str:
    """Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ»Ğ¸ĞºĞ²Ğ¸Ğ´Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ‚Ğ¸ĞºĞµÑ€Ğ°."""
    if ticker in LIQUID_TICKERS:
        return "HIGH"
    if ticker in MEDIUM_TICKERS:
        return "MEDIUM"
    return "LOW"


def _call_ollama(
    ollama_url: str,
    model: str,
    payload: Dict[str, Any],
    max_tokens: int = 500,
    temperature: float = 0.3,
) -> Dict[str, Any]:
    """Ğ’Ñ‹Ğ·Ğ¾Ğ² Ollama API."""
    url = ollama_url.rstrip("/") + "/api/chat"
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": json.dumps(payload, ensure_ascii=False, indent=2)},
    ]

    r = requests.post(
        url,
        json={
            "model": model,
            "messages": messages,
            "stream": False,
            "options": {"num_predict": max_tokens, "temperature": temperature},
        },
        timeout=60,
    )
    r.raise_for_status()
    data = r.json()
    content = data.get("message", {}).get("content", "").strip()

    # Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ JSON Ğ¸Ğ· markdown Ğ±Ğ»Ğ¾ĞºĞ°
    if content.startswith("```"):
        lines = content.split("\n")
        json_lines = [l for l in lines if not l.startswith("```")]
        content = "\n".join(json_lines)

    try:
        return json.loads(content)
    except json.JSONDecodeError:
        logger.warning(f"Failed to parse Qwen response: {content[:200]}")
        return {"skip": False, "raw_text": content}


def _rule_based_analysis(payload: Dict[str, Any]) -> QwenAnalysis:
    """
    ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»Ğ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ±ĞµĞ· LLM.
    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ QwenAnalysis Ñ skip=True ĞµÑĞ»Ğ¸ ÑĞ¸Ğ³Ğ½Ğ°Ğ» Ğ¿Ğ»Ğ¾Ñ…Ğ¾Ğ¹,
    Ğ¸Ğ»Ğ¸ Ñ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞ¾Ğ¹ ĞµÑĞ»Ğ¸ ÑĞ¸Ğ³Ğ½Ğ°Ğ» Ğ¿Ñ€Ğ¸ĞµĞ¼Ğ»ĞµĞ¼Ñ‹Ğ¹.
    """
    anomaly = payload.get("anomaly", {})
    p = payload.get("p", 0)
    direction = payload.get("direction", "LONG")
    horizon = payload.get("horizon", "")
    ticker = payload.get("ticker", "")

    z_ret = anomaly.get("z_ret_5m", 0)
    z_vol = anomaly.get("z_vol_5m", 0)
    spread = anomaly.get("spread_bps") or 0
    volume_spike = anomaly.get("volume_spike", 1.0)

    market = payload.get("market_context", {})
    is_opening = market.get("is_opening", False)
    liquidity = market.get("ticker_liquidity", "MEDIUM")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # SKIP RULES
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    # Rule 1: ĞĞ¸Ğ·ĞºĞ°Ñ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ (calibrated model max â‰ˆ 0.60)
    if p < 0.30:
        return QwenAnalysis(
            skip=True,
            risk_level="HIGH",
            confidence=p,
            reasoning="Ğ’ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ¸Ğ¶Ğµ Ğ¿Ğ¾Ñ€Ğ¾Ğ³Ğ°",
            risk_note="",
            recommendation="SKIP",
            skip_reason=f"p={p:.2f} < 0.30",
        )

    # Rule 2: ĞĞµÑ‚ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ğ¸
    if abs(z_ret) < 0.5 and abs(z_vol) < 0.5:
        return QwenAnalysis(
            skip=True,
            risk_level="HIGH",
            confidence=0.3,
            reasoning="Ğ”Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ğµ Ğ² Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ°Ñ… Ğ½Ğ¾Ñ€Ğ¼Ñ‹",
            risk_note="",
            recommendation="SKIP",
            skip_reason=f"|z_ret|={abs(z_ret):.1f}, |z_vol|={abs(z_vol):.1f} < 0.5",
        )

    # Rule 3: ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ Ğ³Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚ + ÑˆĞ¸Ñ€Ğ¾ĞºĞ¸Ğ¹ ÑĞ¿Ñ€ĞµĞ´
    if horizon in ("5m", "10m") and spread > 25:
        return QwenAnalysis(
            skip=True,
            risk_level="HIGH",
            confidence=0.5,
            reasoning="Ğ¡Ğ¿Ñ€ĞµĞ´ ÑÑŠĞµÑÑ‚ Ğ¿Ñ€Ğ¸Ğ±Ñ‹Ğ»ÑŒ Ğ½Ğ° ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¾Ğ¼ Ğ³Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚Ğµ",
            risk_note="",
            recommendation="SKIP",
            skip_reason=f"spread={spread:.0f}bps Ğ´Ğ»Ñ H={horizon}",
        )

    # Rule 4: ĞÑ‚ĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ² + ÑĞ»Ğ°Ğ±Ñ‹Ğ¹ ÑĞ¸Ğ³Ğ½Ğ°Ğ»
    if is_opening and abs(z_ret) < 1.2:
        return QwenAnalysis(
            skip=True,
            risk_level="HIGH",
            confidence=0.4,
            reasoning="Ğ£Ñ‚Ñ€ĞµĞ½Ğ½ÑÑ Ğ²Ğ¾Ğ»Ğ°Ñ‚Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ, ÑĞ»Ğ°Ğ±Ñ‹Ğ¹ ÑĞ¸Ğ³Ğ½Ğ°Ğ»",
            risk_note="",
            recommendation="SKIP",
            skip_reason="opening + weak signal",
        )

    # Rule 5: SHORT + Ğ½Ğ¸Ğ·ĞºĞ°Ñ Ğ»Ğ¸ĞºĞ²Ğ¸Ğ´Ğ½Ğ¾ÑÑ‚ÑŒ
    if direction == "SHORT" and liquidity == "LOW":
        return QwenAnalysis(
            skip=True,
            risk_level="HIGH",
            confidence=0.4,
            reasoning="Ğ¨Ğ¾Ñ€Ñ‚ Ğ½Ğ¸Ğ·ĞºĞ¾Ğ»Ğ¸ĞºĞ²Ğ¸Ğ´Ğ½Ğ¾Ğ¹ Ğ±ÑƒĞ¼Ğ°Ğ³Ğ¸ Ñ€Ğ¸ÑĞºĞ¾Ğ²Ğ°Ğ½",
            risk_note="",
            recommendation="SKIP",
            skip_reason="SHORT + low liquidity",
        )

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # SCORING (ĞµÑĞ»Ğ¸ Ğ½Ğµ SKIP)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    abs_z_ret = abs(z_ret)

    # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ risk_level Ğ¸ recommendation (calibrated: max p â‰ˆ 0.60)
    if p > 0.45 and abs_z_ret > 1.5 and spread < 20 and volume_spike > 1.3:
        risk_level = "LOW"
        rec_prefix = "STRONG_"
    elif p > 0.38 and abs_z_ret > 1.0 and spread < 35:
        risk_level = "MEDIUM"
        rec_prefix = ""
    else:
        risk_level = "HIGH"
        rec_prefix = "WEAK_"

    # Recommendation based on direction
    if direction == "SHORT":
        recommendation = f"{rec_prefix}SELL" if rec_prefix else "SELL"
    else:
        recommendation = f"{rec_prefix}BUY" if rec_prefix else "BUY"

    # Risk note
    risk_notes = []
    if spread > 30:
        risk_notes.append(f"âš ï¸ Ğ¨Ğ¸Ñ€Ğ¾ĞºĞ¸Ğ¹ ÑĞ¿Ñ€ĞµĞ´ ({spread:.0f} bps)")
    if volume_spike < 1.0:
        risk_notes.append("âš ï¸ ĞĞ±ÑŠÑ‘Ğ¼ Ğ½Ğ¸Ğ¶Ğµ ÑÑ€ĞµĞ´Ğ½ĞµĞ³Ğ¾")
    if is_opening:
        risk_notes.append("âš ï¸ ĞÑ‚ĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²")
    if direction == "SHORT":
        risk_notes.append("ğŸ“‰ SHORT Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ")

    # Reasoning
    vol_note = f"vol_spike={volume_spike:.1f}x" if volume_spike > 1.2 else ""
    reasoning = f"z_ret={z_ret:.1f}, z_vol={z_vol:.1f}, spread={spread:.0f}bps {vol_note}".strip()

    return QwenAnalysis(
        skip=False,
        risk_level=risk_level,
        confidence=p,
        reasoning=reasoning,
        risk_note=" | ".join(risk_notes) if risk_notes else "",
        recommendation=recommendation,
    )


def analyze_signal(
    ollama_url: str,
    model: str,
    payload: Dict[str, Any],
    max_tokens: int = 500,
    temperature: float = 0.3,
    use_rules_only: bool = False,
) -> QwenAnalysis:
    """
    ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²Ñ‹Ğ¹ ÑĞ¸Ğ³Ğ½Ğ°Ğ».

    Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµÑ‚ market_context Ğº payload Ğ¿ĞµÑ€ĞµĞ´ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ¼.
    Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ°Ğ¼Ğ¸, Ğ·Ğ°Ñ‚ĞµĞ¼ (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾) Ñ‡ĞµÑ€ĞµĞ· LLM.
    """
    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ñ€Ñ‹Ğ½ĞºĞ°
    market_context = _get_market_context()
    market_context["ticker_liquidity"] = _get_ticker_liquidity(payload.get("ticker", ""))
    payload["market_context"] = market_context

    # Rule-based Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·
    rule_result = _rule_based_analysis(payload)

    # Ğ•ÑĞ»Ğ¸ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ° ÑĞºĞ°Ğ·Ğ°Ğ»Ğ¸ SKIP â€” ÑÑ€Ğ°Ğ·Ñƒ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼
    if rule_result.skip:
        logger.debug(f"Signal rejected by rules: {rule_result.skip_reason}")
        return rule_result

    # Ğ•ÑĞ»Ğ¸ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ° â€” Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ rule_result
    if use_rules_only:
        return rule_result

    # Ğ’Ñ‹Ğ·Ğ¾Ğ² LLM Ğ´Ğ»Ñ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°
    try:
        response = _call_ollama(ollama_url, model, payload, max_tokens, temperature)
    except Exception as e:
        logger.warning(f"Ollama failed, using rules: {e}")
        return rule_result

    # ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ LLM Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°
    skip = response.get("skip", False)

    return QwenAnalysis(
        skip=skip,
        risk_level=response.get("risk_level", rule_result.risk_level),
        confidence=float(response.get("confidence", payload.get("p", 0.5))),
        reasoning=response.get("reasoning", rule_result.reasoning),
        risk_note=response.get("risk_note", rule_result.risk_note),
        recommendation=response.get("recommendation", rule_result.recommendation),
        skip_reason=response.get("skip_reason") if skip else None,
        raw_response=response,
    )


def format_telegram_message(
    ticker: str,
    horizon: str,
    p: float,
    analysis: QwenAnalysis,
    direction: str = "LONG",
    entry: Optional[float] = None,
    take: Optional[float] = None,
    stop: Optional[float] = None,
    anomaly_score: float = 0,
    volume_spike: float = 1.0,
) -> str:
    """Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Telegram."""

    # Ğ­Ğ¼Ğ¾Ğ´Ğ·Ğ¸ Ğ¿Ğ¾ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸
    emoji_map = {
        "STRONG_BUY": "ğŸŸ¢ğŸŸ¢",
        "BUY": "ğŸŸ¢",
        "WEAK_BUY": "ğŸŸ¡",
        "STRONG_SELL": "ğŸ”´ğŸ”´",
        "SELL": "ğŸ”´",
        "WEAK_SELL": "ğŸŸ ",
        "SKIP": "âš«",
    }
    emoji = emoji_map.get(analysis.recommendation, "âšª")

    # Direction emoji
    dir_emoji = "ğŸ“ˆ" if direction == "LONG" else "ğŸ“‰"

    # Risk
    risk_emoji = {"LOW": "âœ…", "MEDIUM": "âš ï¸", "HIGH": "ğŸ”´"}.get(analysis.risk_level, "")

    lines = [
        f"{emoji} **{ticker}** {dir_emoji} {direction} | {horizon}",
        f"ğŸ“Š p={p:.0%} | score={anomaly_score:.1f} | vol={volume_spike:.1f}x",
    ]

    if entry and take and stop:
        lines.append(f"ğŸ’° Entry: {entry:.2f} â†’ Take: {take:.2f} | Stop: {stop:.2f}")

    lines.append(f"{risk_emoji} Risk: {analysis.risk_level} | {analysis.recommendation}")

    if analysis.reasoning:
        lines.append(f"ğŸ’¡ {analysis.reasoning}")

    if analysis.risk_note:
        lines.append(analysis.risk_note)

    return "\n".join(lines)


# Legacy API
def explain_with_qwen(
    ollama_url: str,
    model: str,
    payload: Dict[str, Any],
    max_tokens: int = 350,
    temperature: float = 0.3,
) -> Dict[str, Any]:
    """Legacy Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸."""
    analysis = analyze_signal(
        ollama_url=ollama_url,
        model=model,
        payload=payload,
        max_tokens=max_tokens,
        temperature=temperature,
    )
    return {
        "skip": analysis.skip,
        "skip_reason": analysis.skip_reason,
        "risk_level": analysis.risk_level,
        "confidence": analysis.confidence,
        "reasoning": analysis.reasoning,
        "risk_note": analysis.risk_note,
        "recommendation": analysis.recommendation,
    }
