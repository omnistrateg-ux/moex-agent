#!/usr/bin/env python3
"""
–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–µ–π –≤ Replit.

–ó–∞–ø—É—Å–∫:
    python scripts/retrain.py [--days 30] [--horizon 5m]

–ü—Ä–∏–º–µ—Ä—ã:
    python scripts/retrain.py                    # –í—Å–µ –º–æ–¥–µ–ª–∏, 30 –¥–Ω–µ–π
    python scripts/retrain.py --days 60          # –í—Å–µ –º–æ–¥–µ–ª–∏, 60 –¥–Ω–µ–π
    python scripts/retrain.py --horizon 5m       # –¢–æ–ª—å–∫–æ 5-–º–∏–Ω—É—Ç–Ω–∞—è –º–æ–¥–µ–ª—å
    python scripts/retrain.py --no-backup        # –ë–µ–∑ –±—ç–∫–∞–ø–∞ —Å—Ç–∞—Ä—ã—Ö –º–æ–¥–µ–ª–µ–π
"""

import argparse
import json
import logging
import shutil
import sys
from datetime import datetime
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞
ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(ROOT))

import joblib
import numpy as np
import pandas as pd
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import TimeSeriesSplit

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(message)s",
    datefmt="%H:%M:%S",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(ROOT / "data" / "retrain.log"),
    ],
)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
MODEL_PARAMS = {
    "n_estimators": 100,
    "max_depth": 5,
    "learning_rate": 0.1,
    "min_samples_split": 50,
    "min_samples_leaf": 20,
    "random_state": 42,
}

HORIZONS = ["5m", "10m", "30m", "1h"]
N_SPLITS = 5
MODELS_DIR = ROOT / "models"
BACKUP_DIR = MODELS_DIR / "backup"


def load_data(days: int) -> pd.DataFrame:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å MOEX."""
    from moex_agent.bootstrap import bootstrap_recent
    from moex_agent.config_schema import load_config
    from moex_agent.storage import connect

    logger.info(f"üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å MOEX ({days} –¥–Ω–µ–π)...")

    config = load_config()
    conn = connect(config.sqlite_path)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—É—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    cur = conn.execute("SELECT COUNT(*) as cnt FROM candles")
    before = cur.fetchone()["cnt"]

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ
    try:
        bootstrap_recent(conn, config, days=days)
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ
    cur = conn.execute("SELECT COUNT(*) as cnt FROM candles")
    after = cur.fetchone()["cnt"]

    logger.info(f"   –ë—ã–ª–æ: {before:,} ‚Üí –°—Ç–∞–ª–æ: {after:,} —Å–≤–µ—á–µ–π")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
    df = pd.read_sql("SELECT * FROM candles ORDER BY secid, ts", conn)
    conn.close()

    return df


def build_features_for_ticker(ticker_df: pd.DataFrame) -> pd.DataFrame:
    """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å —Ñ–∏—á–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–∏–∫–µ—Ä–∞."""
    from moex_agent.features import FEATURE_COLS, build_feature_frame

    candles = ticker_df.to_dict("records")
    features_df = build_feature_frame(candles)

    return features_df[FEATURE_COLS]


def create_labels_for_horizon(df: pd.DataFrame, horizon: str) -> pd.Series:
    """–°–æ–∑–¥–∞—Ç—å –º–µ—Ç–∫–∏ –¥–ª—è –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞."""
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–∏–æ–¥ –≤ –º–∏–Ω—É—Ç–∞—Ö
    periods = {"5m": 5, "10m": 10, "30m": 30, "1h": 60}
    period = periods.get(horizon, 5)

    # –ë—É–¥—É—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
    future_return = df["close"].shift(-period) / df["close"] - 1

    # 1 –µ—Å–ª–∏ —Ä–æ—Å—Ç, 0 –µ—Å–ª–∏ –ø–∞–¥–µ–Ω–∏–µ
    labels = (future_return > 0).astype(int)

    return labels


def train_model(X: pd.DataFrame, y: pd.Series, n_splits: int = 5) -> tuple:
    """Walk-Forward –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏."""
    tscv = TimeSeriesSplit(n_splits=n_splits)

    results = []
    best_model = None
    best_score = 0

    for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):
        X_train = X.iloc[train_idx]
        X_test = X.iloc[test_idx]
        y_train = y.iloc[train_idx]
        y_test = y.iloc[test_idx]

        model = GradientBoostingClassifier(**MODEL_PARAMS)
        model.fit(X_train, y_train)

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        y_pred = model.predict(X_test)
        y_prob = model.predict_proba(X_test)[:, 1]

        # –ú–µ—Ç—Ä–∏–∫–∏
        accuracy = (y_pred == y_test).mean()

        # Win Rate –¥–ª—è –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        high_conf = y_prob > 0.55
        if high_conf.sum() > 0:
            wins = ((y_pred == y_test) & high_conf).sum()
            win_rate = wins / high_conf.sum()
        else:
            win_rate = 0.5

        results.append({
            "fold": fold + 1,
            "accuracy": accuracy,
            "win_rate": win_rate,
            "trades": int(high_conf.sum()),
        })

        logger.info(f"   Fold {fold + 1}: acc={accuracy:.3f}, wr={win_rate:.3f}, trades={high_conf.sum()}")

        if accuracy > best_score:
            best_score = accuracy
            best_model = model

    # –°—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
    avg_metrics = {
        "accuracy": np.mean([r["accuracy"] for r in results]),
        "win_rate": np.mean([r["win_rate"] for r in results]),
        "trades": int(np.mean([r["trades"] for r in results])),
    }

    return best_model, avg_metrics


def backup_models():
    """–°–æ–∑–¥–∞—Ç—å –±—ç–∫–∞–ø —Ç–µ–∫—É—â–∏—Ö –º–æ–¥–µ–ª–µ–π."""
    BACKUP_DIR.mkdir(exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_path = BACKUP_DIR / timestamp
    backup_path.mkdir(exist_ok=True)

    for model_file in MODELS_DIR.glob("*.joblib"):
        shutil.copy(model_file, backup_path / model_file.name)

    meta_file = MODELS_DIR / "meta.json"
    if meta_file.exists():
        shutil.copy(meta_file, backup_path / "meta.json")

    logger.info(f"üíæ –ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω: {backup_path}")
    return backup_path


def send_notification(message: str):
    """–û—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ Telegram."""
    try:
        from moex_agent.telegram import send_telegram
        send_telegram(message)
        logger.info("üì± –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ Telegram")
    except Exception as e:
        logger.warning(f"Telegram: {e}")


def main():
    parser = argparse.ArgumentParser(description="–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–µ–π")
    parser.add_argument("--days", type=int, default=30, help="–î–Ω–µ–π –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
    parser.add_argument("--horizon", type=str, help="–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≥–æ—Ä–∏–∑–æ–Ω—Ç (5m/10m/30m/1h)")
    parser.add_argument("--no-backup", action="store_true", help="–ù–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å –±—ç–∫–∞–ø")
    parser.add_argument("--no-notify", action="store_true", help="–ù–µ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –≤ Telegram")
    args = parser.parse_args()

    logger.info("=" * 50)
    logger.info("üöÄ MOEX Agent ‚Äî –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")
    logger.info("=" * 50)

    # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫–∏
    MODELS_DIR.mkdir(exist_ok=True)
    (ROOT / "data").mkdir(exist_ok=True)

    # –ë—ç–∫–∞–ø
    if not args.no_backup:
        backup_models()

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df = load_data(args.days)

    if len(df) < 10000:
        logger.error("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!")
        sys.exit(1)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç—ã
    horizons = [args.horizon] if args.horizon else HORIZONS

    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    meta = {
        "trained_at": datetime.now().isoformat(),
        "platform": "Replit",
        "days_of_data": args.days,
        "candles_used": len(df),
        "horizons": {},
    }

    # –û–±—É—á–µ–Ω–∏–µ
    for horizon in horizons:
        logger.info(f"\nüîÑ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ {horizon}...")

        all_X = []
        all_y = []

        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —Ç–∏–∫–µ—Ä–∞–º
        for ticker in df["secid"].unique():
            ticker_df = df[df["secid"] == ticker].copy()

            if len(ticker_df) < 500:
                continue

            try:
                # –§–∏—á–∏
                X = build_features_for_ticker(ticker_df)

                # –ú–µ—Ç–∫–∏
                y = create_labels_for_horizon(ticker_df, horizon)

                # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º
                min_len = min(len(X), len(y))
                X = X.iloc[:min_len]
                y = y.iloc[:min_len]

                all_X.append(X)
                all_y.append(y)

            except Exception as e:
                logger.warning(f"   {ticker}: –æ—à–∏–±–∫–∞ - {e}")
                continue

        if not all_X:
            logger.error(f"   ‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {horizon}")
            continue

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º
        X = pd.concat(all_X, ignore_index=True)
        y = pd.concat(all_y, ignore_index=True)

        # –£–±–∏—Ä–∞–µ–º NaN
        mask = ~(X.isna().any(axis=1) | y.isna())
        X = X[mask].reset_index(drop=True)
        y = y[mask].reset_index(drop=True)

        logger.info(f"   –î–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(X):,}")

        # –û–±—É—á–µ–Ω–∏–µ
        model, metrics = train_model(X, y, N_SPLITS)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        model_path = MODELS_DIR / f"model_time_{horizon}.joblib"
        joblib.dump(model, model_path)

        logger.info(f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {model_path.name}")
        logger.info(f"   üìà WR={metrics['win_rate']:.1%}, Acc={metrics['accuracy']:.1%}")

        meta["horizons"][horizon] = {
            "win_rate": round(metrics["win_rate"], 3),
            "accuracy": round(metrics["accuracy"], 3),
            "trades": metrics["trades"],
        }

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    with open(MODELS_DIR / "meta.json", "w") as f:
        json.dump(meta, f, indent=2, ensure_ascii=False)

    # –ò—Ç–æ–≥
    logger.info("\n" + "=" * 50)
    logger.info("‚úÖ –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    logger.info("=" * 50)

    for h, m in meta["horizons"].items():
        logger.info(f"   {h}: WR={m['win_rate']:.1%}, Acc={m['accuracy']:.1%}")

    # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
    if not args.no_notify:
        results = ", ".join([f"{h}={m['win_rate']:.0%}" for h, m in meta["horizons"].items()])
        send_notification(f"‚úÖ –ú–æ–¥–µ–ª–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω—ã!\n{results}")


if __name__ == "__main__":
    main()
